{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "import random as rnd\n",
    "\n",
    "from svm_qf import *"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(predictor, X, y, grid_size, filename):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, grid_size),\n",
    "                         np.linspace(y_min, y_max, grid_size),\n",
    "                         indexing='ij')\n",
    "    flatten = lambda m: np.array(m).reshape(-1,)\n",
    "\n",
    "    result = []\n",
    "    for (i, j) in itertools.product(range(grid_size), range(grid_size)):\n",
    "        point = np.array([xx[i, j], yy[i, j]]).reshape(1, 2)\n",
    "        result.append(predictor.predict(point))\n",
    "\n",
    "    Z = np.array(result).reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z,\n",
    "                 cmap=cm.Paired,\n",
    "                 levels=[-0.001, 0.001],\n",
    "                 extend='both',\n",
    "                 alpha=0.8)\n",
    "    plt.scatter(flatten(X[:, 0]), flatten(X[:, 1]),\n",
    "                c=flatten(y), cmap=cm.Paired)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def f1score(theory, practice):\n",
    "    tp, fn, fp, tn = 0, 0, 0, 0\n",
    "    for i in range(len(theory)):\n",
    "        tp += theory[i] == practice[i] and practice[i] == 1\n",
    "        tn += theory[i] == practice[i] and practice[i] == 0\n",
    "        fn = sum(practice) - tp\n",
    "        fp = (len(practice) - sum(practice)) - tn\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    \"\"\"\n",
    "        http://cs229.stanford.edu/materials/smo.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=10000, kernel_type='linear', C=1.0, epsilon=0.001):\n",
    "        self.kernels = {\n",
    "            'linear' : self.kernel_linear,\n",
    "            'quadratic' : self.kernel_quadratic,\n",
    "            'gaussian' : self.kernel_gaussian\n",
    "        }\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel_type = kernel_type\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Initialization\n",
    "        n, d = X.shape[0], X.shape[1]\n",
    "        alpha = np.zeros((n))\n",
    "        kernel = self.kernels[self.kernel_type]\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            alpha_prev = np.copy(alpha)\n",
    "            for j in range(0, n):\n",
    "                i = self.get_rnd_int(0, n-1, j) # Get random int i~=j\n",
    "                x_i, x_j, y_i, y_j = X[i,:], X[j,:], y[i], y[j]\n",
    "                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
    "                if k_ij == 0:\n",
    "                    continue\n",
    "                alpha_prime_j, alpha_prime_i = alpha[j], alpha[i]\n",
    "                (L, H) = self.compute_L_H(self.C, alpha_prime_j, alpha_prime_i, y_j, y_i)\n",
    "\n",
    "                # Compute model parameters\n",
    "                self.w = self.calc_w(alpha, y, X)\n",
    "                self.b = self.calc_b(X, y, self.w)\n",
    "\n",
    "                # Compute E_i, E_j\n",
    "                E_i = self.E(x_i, y_i, self.w, self.b)\n",
    "                E_j = self.E(x_j, y_j, self.w, self.b)\n",
    "\n",
    "                # Set new alpha values\n",
    "                alpha[j] = alpha_prime_j + float(y_j * (E_i - E_j))/k_ij\n",
    "                alpha[j] = max(alpha[j], L)\n",
    "                alpha[j] = min(alpha[j], H)\n",
    "\n",
    "                alpha[i] = alpha_prime_i + y_i*y_j * (alpha_prime_j - alpha[j])\n",
    "\n",
    "            # Check convergence\n",
    "            diff = np.linalg.norm(alpha - alpha_prev)\n",
    "            if diff < self.epsilon:\n",
    "                break\n",
    "\n",
    "            if count >= self.max_iter:\n",
    "                print(\"Iteration number exceeded the max of %d iterations\" % (self.max_iter))\n",
    "                return\n",
    "        # Compute final model parameters\n",
    "        self.b = self.calc_b(X, y, self.w)\n",
    "        if self.kernel_type == 'linear':\n",
    "            self.w = self.calc_w(alpha, y, X)\n",
    "        # Get support vectors\n",
    "        alpha_idx = np.where(alpha > 0)[0]\n",
    "        #pprint(\"support vectors:\")\n",
    "        #pprint(alpha_idx)\n",
    "        support_vectors = X[alpha_idx, :]\n",
    "        return support_vectors, count\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.h(X, self.w, self.b)\n",
    "    def calc_b(self, X, y, w):\n",
    "        b_tmp = y - np.dot(w.T, X.T)\n",
    "        return np.mean(b_tmp)\n",
    "    def calc_w(self, alpha, y, X):\n",
    "        return np.dot(alpha * y, X)\n",
    "    # Prediction\n",
    "    def h(self, X, w, b):\n",
    "        return np.sign(np.dot(w.T, X.T) + b).item() #.astype(int)\n",
    "    # Prediction error\n",
    "    def E(self, x_k, y_k, w, b):\n",
    "        return self.h(x_k, w, b) - y_k\n",
    "    def compute_L_H(self, C, alpha_prime_j, alpha_prime_i, y_j, y_i):\n",
    "        if(y_i != y_j):\n",
    "            return (max(0, alpha_prime_j - alpha_prime_i), min(C, C - alpha_prime_i + alpha_prime_j))\n",
    "        else:\n",
    "            return (max(0, alpha_prime_i + alpha_prime_j - C), min(C, alpha_prime_i + alpha_prime_j))\n",
    "    def get_rnd_int(self, a,b,z):\n",
    "        i = z\n",
    "        while i == z:\n",
    "            i = rnd.randint(a,b)\n",
    "        return i\n",
    "    # Define kernels\n",
    "    def kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "    def kernel_quadratic(self, x1, x2):\n",
    "        return (np.dot(x1, x2.T) ** 2)  \n",
    "    def kernel_gaussian(self, x, y):\n",
    "        sigma = 0.06\n",
    "        exponent = -np.sqrt(la.norm(x-y) ** 2 / (2 * sigma ** 2))\n",
    "        return np.exp(exponent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(num_samples=50, num_features=2): \n",
    "    samples = np.array([np.random.normal(size=num_samples) for i in range(num_features)]).T\n",
    "    labels = 2 * (samples.sum(axis=1) > 0) - 1.0\n",
    "    labels = np.array([[i] for i in labels])\n",
    "    return np.concatenate((samples, labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = generate(150)\n",
    "def __plot(data):\n",
    "    x = data[:, 0]\n",
    "    y = data[:, 1]\n",
    "    color = [\"red\" if x > 0 else \"blue\" for x in data[:, 2]]\n",
    "    plt.scatter(x,y,c=color)\n",
    "__plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test, learn = data[30:], data[30:]\n",
    "X = learn[:,[0,1]]\n",
    "y = learn[:,2].reshape(learn[:,2].shape[0], 1)\n",
    "# pprint(X.shape) # (40, 2)\n",
    "# pprint(y.shape) # (40, 1)\n",
    "QF_SVN_trainer = SVMTrainer(Kernel.gaussian(0.6), 1.0)\n",
    "QF_SVN_predictor = QF_SVN_trainer.train(X, y)\n",
    "predicted = []\n",
    "y0 = [0 if i < 0 else 1 for i in test[:,2]]\n",
    "for i in test:\n",
    "    ans = QF_SVN_predictor.predict((i[[0,1]]))\n",
    "    res = int(ans)\n",
    "    if (res < 0):\n",
    "        res = 0\n",
    "    predicted.append(res)\n",
    "    #pprint((ans, i[2]))\n",
    "f1score(y0, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svn = SVM()\n",
    "y = learn[:,2]\n",
    "sv, ite = svn.fit(X, y) # pprint(y.shape) #(40,)\n",
    "for i in test:\n",
    "    ans = svn.predict((i[[0,1]]))\n",
    "    pprint((ans, i[2]))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"chips.txt\", header=None, names=[\"x\", \"y\", \"type\"])\n",
    "df['color'] = df['type'].map(lambda x: 'red' if x else 'blue')\n",
    "df['svn_type'] = df['type'].map(lambda x: -1 if x == 0 else 1)\n",
    "r, phi = zip(*[cart2pol(i[0], i[1]) for i in zip(list(df['x']), list(df['y']))])\n",
    "plt.scatter(r, phi, c=df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_y_type = np.array(list(zip(df['x'], df['y'], df['svn_type'])))\n",
    "kf = KFold(len(x_y_type), n_folds=5,shuffle=True)\n",
    "f1scores = []\n",
    "f1scores2 = []\n",
    "for train_index, test_index in kf:   \n",
    "    svn = SVM(kernel_type='gaussian')\n",
    "    cur_X = x_y_type[train_index][:, [0,1]]\n",
    "    cur_y = x_y_type[train_index][:, 2].astype(int)\n",
    "    svn.fit(cur_X, cur_y)\n",
    "    res = [svn.predict(np.array(x)) for *x, y in x_y_type[test_index]]\n",
    "    y = x_y_type[test_index][: , 2].astype(int)\n",
    "    fres = [0 if i < 0 else 1 for i in res]\n",
    "    fy = [0 if i < 0 else 1 for i in y]\n",
    "    f1scores.append(f1score(fy, fres))\n",
    "    \n",
    "    QF_SVN_trainer = SVMTrainer(Kernel.gaussian(0.6), 1.0)\n",
    "    X = cur_X.astype(float)\n",
    "    y = cur_y.reshape(cur_y.shape[0], 1).astype(float)\n",
    "    pprint(X.shape)\n",
    "    pprint(y.shape)\n",
    "    QF_SVN_predictor = QF_SVN_trainer.train(X, y)\n",
    "    res2 = [QF_SVN_predictor.predict(np.array(x)) for *x, y in x_y_type[test_index]]\n",
    "    y = x_y_type[test_index][: , 2].astype(int)\n",
    "    fres2 = [0 if i < 0 else 1 for i in res2]\n",
    "    fy = [0 if i < 0 else 1 for i in y]\n",
    "    f1scores2.append(f1score(fy, fres2))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(f1scores)\n",
    "pprint(f1scores2)\n",
    "np.mean(f1scores)\n",
    "np.mean(f1scores2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}